{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "90ac80ca41fde58b95f02cc0cfc0a0f2ed3115615ffe1bdfdfc10fd5ffeef9a4"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# **Data Wrangling Lab**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this assignment you will be performing data wrangling.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "-   Identify duplicate values in the dataset.\n\n-   Remove duplicate values from the dataset.\n\n-   Identify missing values in the dataset.\n\n-   Impute the missing values in the dataset.\n\n-   Normalize data in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Import pandas module.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-7-7dd3504c366f>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "Load the dataset into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read Data</h2>\n<p>\nWe utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The functions below will download the dataset into your browser:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "To obtain the dataset, utilize the download() function as defined above:  \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "await download(file_path, \"m1_survey_data.csv\")\nfile_name=\"m1_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "Utilize the Pandas method read_csv() to load the data into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(file_name)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "## Finding duplicates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this section you will identify duplicate values in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " Find how many duplicate rows exist in the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\nduplicates = df[df.duplicated()]\nprint(f\"Number of Duplicates found are : {duplicates.shape[0]}\")\nprint(f\"Sample Duplicates are :\")\nprint(duplicates.head(5))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of Duplicates found are : 154\nSample Duplicates are :\n      Respondent                      MainBranch Hobbyist  \\\n1168        2339  I am a developer by profession      Yes   \n1169        2342  I am a developer by profession      Yes   \n1170        2343  I am a developer by profession      Yes   \n1171        2344  I am a developer by profession      Yes   \n1172        2347  I am a developer by profession      Yes   \n\n                                            OpenSourcer  \\\n1168                         Once a month or more often   \n1169                                              Never   \n1170  Less than once a month but more than once per ...   \n1171                                              Never   \n1172                                              Never   \n\n                                             OpenSource          Employment  \\\n1168  OSS is, on average, of HIGHER quality than pro...  Employed full-time   \n1169  The quality of OSS and closed source software ...  Employed full-time   \n1170  OSS is, on average, of LOWER quality than prop...  Employed full-time   \n1171  The quality of OSS and closed source software ...  Employed full-time   \n1172  OSS is, on average, of HIGHER quality than pro...  Employed full-time   \n\n             Country Student  \\\n1168   United States      No   \n1169  United Kingdom      No   \n1170          Canada      No   \n1171   United States      No   \n1172  United Kingdom      No   \n\n                                                EdLevel  \\\n1168  Some college/university study without earning ...   \n1169  Some college/university study without earning ...   \n1170        Master’s degree (MA, MS, M.Eng., MBA, etc.)   \n1171           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n1172        Master’s degree (MA, MS, M.Eng., MBA, etc.)   \n\n                                         UndergradMajor  ...  \\\n1168  Computer science, computer engineering, or sof...  ...   \n1169  Information systems, information technology, o...  ...   \n1170  Computer science, computer engineering, or sof...  ...   \n1171  Computer science, computer engineering, or sof...  ...   \n1172  Computer science, computer engineering, or sof...  ...   \n\n                                 WelcomeChange  \\\n1168   Just as welcome now as I felt last year   \n1169  Somewhat more welcome now than last year   \n1170  Somewhat more welcome now than last year   \n1171   Just as welcome now as I felt last year   \n1172   Just as welcome now as I felt last year   \n\n                                           SONewContent   Age Gender Trans  \\\n1168                                                NaN  24.0    Man    No   \n1169  Tech meetups or events in your area;Courses on...  24.0    Man    No   \n1170  Tech articles written by other developers;Indu...  27.0    Man    No   \n1171  Tech articles written by other developers;Indu...  24.0    Man    No   \n1172                                                NaN   NaN  Woman    No   \n\n                    Sexuality  \\\n1168  Straight / Heterosexual   \n1169  Straight / Heterosexual   \n1170  Straight / Heterosexual   \n1171  Straight / Heterosexual   \n1172  Straight / Heterosexual   \n\n                                              Ethnicity Dependents  \\\n1168                       White or of European descent         No   \n1169                       White or of European descent         No   \n1170  Black or of African descent;White or of Europe...         No   \n1171                       White or of European descent         No   \n1172                                           Biracial         No   \n\n               SurveyLength                  SurveyEase  \n1168  Appropriate in length                        Easy  \n1169               Too long                        Easy  \n1170  Appropriate in length  Neither easy nor difficult  \n1171  Appropriate in length                        Easy  \n1172               Too long                        Easy  \n\n[5 rows x 85 columns]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "## Removing duplicates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Remove the duplicate rows from the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf_cleaned = df.drop_duplicates()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "Verify if duplicates were actually dropped.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\nprint(f\"Duplicates removed : {df.shape[0]-df_cleaned.shape[0]}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Duplicates removed : 154\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "## Finding Missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the missing values for all columns.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\nmissing_values = df_cleaned.isna().sum()\nprint(f\"Missing Values :\")\nprint(missing_values)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Missing Values :\nRespondent        0\nMainBranch        0\nHobbyist          0\nOpenSourcer       0\nOpenSource       81\n               ... \nSexuality       542\nEthnicity       675\nDependents      140\nSurveyLength     19\nSurveyEase       14\nLength: 85, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "Find out how many rows are missing in the column 'WorkLoc'\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\nmissing_WorkLoc = df_cleaned['WorkLoc'].isna().sum()\nprint(f\"Missing workLoc : \")\nprint(missing_WorkLoc)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Missing workLoc : \n32\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": "## Imputing missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the  value counts for the column WorkLoc.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\nvalue_counts = df_cleaned['WorkLoc'].value_counts()\nprint(\"\\nValue counts for 'WorkLoc':\")\nprint(value_counts)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nValue counts for 'WorkLoc':\nWorkLoc\nOffice                                            6806\nHome                                              3589\nOther place, such as a coworking space or cafe     971\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": "Identify the value that is most frequent (majority) in the WorkLoc column.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#make a note of the majority value here, for future reference\n#\nmost_frequent_value = value_counts.idxmax()\nprint(f\"\\nMost frequent value in 'WorkLoc': {most_frequent_value}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nMost frequent value in 'WorkLoc': Office\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf['WorkLoc'].fillna(most_frequent_value, inplace = True) ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": "After imputation there should ideally not be any empty rows in the WorkLoc column.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Verify if imputing was successful.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\nmissing_workloc_after_imputation = df_cleaned['WorkLoc'].isna().sum()\nprint(f\"\\nNumber of missing values in 'WorkLoc' after imputation: {missing_workloc_after_imputation}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nNumber of missing values in 'WorkLoc' after imputation: 32\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "source": "## Normalizing data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "There are two columns in the dataset that talk about compensation.\n\nOne is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n\nThe other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n\nThis makes it difficult to compare the total compensation of the developers.\n\nIn this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n\nOnce this column is ready, it makes comparison of salaries easy.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "List out the various categories in the column 'CompFreq'\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ncomp_freq_categories = df_cleaned['CompFreq'].unique()\nprint(\"Categories in 'CompFreq':\")\nprint(comp_freq_categories)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Categories in 'CompFreq':\n['Yearly' 'Monthly' 'Weekly' nan]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 36
    },
    {
      "cell_type": "markdown",
      "source": "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Double click to see the **Hint**.\n\n<!--\n\nUse the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n\nIf the CompFreq is Yearly then use the exising value in CompTotal\nIf the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\nIf the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndef normalize_annual_compensation(row):\n    if row['CompFreq'] == 'Yearly':\n        return row['CompTotal']\n    elif row['CompFreq'] == 'Monthly':\n        return row['CompTotal'] * 12\n    elif row['CompFreq'] == 'Weekly':\n        return row['CompTotal'] * 52\n    else:\n        return None\ndf_cleaned['NormalizedAnnualCompensation'] = df_cleaned.apply(normalize_annual_compensation, axis=1)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<!--## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |--!>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}